import streamlit as st
import cv2
import numpy as np
import os
import time
import av
import joblib
from streamlit_drawable_canvas import st_canvas
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration, WebRtcMode
from streamlit_image_coordinates import streamlit_image_coordinates

# --------------------------------------------------------------------------------
# ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´åº«é…ç½®
# --------------------------------------------------------------------------------
# è¨­å®š TensorFlow æ—¥èªŒç­‰ç´šï¼Œéš±è—éå¿…è¦çš„è­¦å‘Šè¨Šæ¯ï¼Œä¿æŒçµ‚ç«¯æ©Ÿè¼¸å‡ºä¹¾æ·¨
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
from tensorflow.keras.models import load_model
from tensorflow.keras.datasets import mnist
from sklearn.neighbors import KNeighborsClassifier

# --------------------------------------------------------------------------------
# å…¨åŸŸåƒæ•¸è¨­å®š
# --------------------------------------------------------------------------------
MIN_HEIGHT = 50           # åµæ¸¬æ¡†çš„æœ€å°é«˜åº¦ï¼Œéå°çš„å€å¡Šå°‡è¢«è¦–ç‚ºé›œè¨Šå¿½ç•¥
MIN_AREA = 500            # è¼ªå»“çš„æœ€å°é¢ç©é–¾å€¼
SHRINK_PX = 4             # ç¹ªè£½çµæœæ¡†æ™‚ï¼Œå‘å…§ç¸®æ¸›çš„åƒç´ é‡ï¼ˆç¾è§€ç”¨ï¼‰
STABILITY_DURATION = 1.2  # é¡é ­æ¨¡å¼ä¸‹ï¼Œéœ€ä¿æŒç•«é¢ç©©å®šçš„æ™‚é–“ï¼ˆç§’ï¼‰æ‰èƒ½è§¸ç™¼è‡ªå‹•æŠ“æ‹
MOVEMENT_THRESHOLD = 80   # ç•«é¢è®Šå‹•åˆ¤å®šé–¾å€¼ï¼Œä½æ–¼æ­¤å€¼è¦–ç‚ºç©©å®š
CONFIDENCE_THRESHOLD = 0.85 # CNN æ¨¡å‹ä¿¡å¿ƒåº¦é–€æª»ï¼Œä½æ–¼æ­¤å€¼ä¸é¡¯ç¤ºçµæœ
KNN_VERIFY_RANGE = (0.85, 0.95) # è§¸ç™¼ KNN äºŒæ¬¡é©—è­‰çš„ä¿¡å¿ƒåº¦å€é–“ï¼ˆæ¨¡ç³Šåœ°å¸¶ï¼‰
ROI_MARGIN_X = 60         # é¡é ­æ¨¡å¼æ„Ÿèˆˆè¶£å€åŸŸ (ROI) çš„ X è»¸é‚Šè·
ROI_MARGIN_Y = 60         # é¡é ­æ¨¡å¼æ„Ÿèˆˆè¶£å€åŸŸ (ROI) çš„ Y è»¸é‚Šè·
TEXT_Y_OFFSET = 15        # ç¹ªè£½æ–‡å­—æ¨™ç±¤æ™‚çš„ Y è»¸åç§»é‡

# --------------------------------------------------------------------------------
# 1. æ¨¡å‹è¼‰å…¥èˆ‡åˆå§‹åŒ–æ¨¡çµ„
# --------------------------------------------------------------------------------
@st.cache_resource
def load_ai_models():
    """
    è¼‰å…¥ CNN ä¸»æ¨¡å‹èˆ‡ KNN è¼”åŠ©æ¨¡å‹ã€‚
    ä½¿ç”¨ @st.cache_resource ç¢ºä¿åœ¨ Streamlit é‡è·‘æ™‚ä¸æœƒé‡è¤‡è¼‰å…¥æ¨¡å‹ï¼Œæå‡æ•ˆèƒ½ã€‚
    """
    cnn = None
    # å˜—è©¦è¼‰å…¥é è¨“ç·´å¥½çš„ CNN æ¨¡å‹ (H5 æ ¼å¼)
    if os.path.exists("mnist_cnn.h5"):
        try:
            cnn = load_model("mnist_cnn.h5")
            print("âœ… CNN æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        except:
            print("âŒ CNN æ¨¡å‹è¼‰å…¥å¤±æ•—")
    
    knn = None
    knn_path = "knn_model.pkl"
    # å˜—è©¦è¼‰å…¥ KNN æ¨¡å‹ï¼Œè‹¥ä¸å­˜åœ¨æˆ–æå£å‰‡é‡æ–°è¨“ç·´
    if os.path.exists(knn_path):
        try:
            knn = joblib.load(knn_path)
            print("âœ… KNN æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        except:
            print("âš ï¸ KNN æ¨¡å‹æå£ï¼Œé‡æ–°è¨“ç·´...")
    
    # è‹¥ç„¡ KNN æ¨¡å‹ï¼Œå‰‡ä½¿ç”¨ MNIST æ•¸æ“šé›†é€²è¡Œå¿«é€Ÿè¨“ç·´ (K=3)
    if knn is None:
        print("â³ æ­£åœ¨è¨“ç·´ KNN è¼”åŠ©æ¨¡å‹ (åƒ…éœ€ä¸€æ¬¡)...")
        try:
            (x_train, y_train), _ = mnist.load_data()
            x_flat = x_train.reshape(-1, 784) / 255.0
            knn = KNeighborsClassifier(n_neighbors=3)
            knn.fit(x_flat[:10000], y_train[:10000]) # åƒ…ä½¿ç”¨å‰ 10000 ç­†è³‡æ–™ä»¥åŠ é€Ÿ
            joblib.dump(knn, knn_path)
            print("âœ… KNN æ¨¡å‹è¨“ç·´å®Œæˆä¸¦å„²å­˜")
        except Exception as e:
            print(f"âŒ KNN è¨“ç·´å¤±æ•—: {e}")
            knn = None
    return cnn, knn

# åˆå§‹åŒ–å…¨åŸŸæ¨¡å‹è®Šæ•¸
model, knn_model = load_ai_models()

# --------------------------------------------------------------------------------
# 2. æ ¸å¿ƒå½±åƒæ¼”ç®—æ³• (é€šç”¨è™•ç†)
# --------------------------------------------------------------------------------
def center_by_moments_cnn(src):
    """
    åˆ©ç”¨å½±åƒçŸ© (Moments) è¨ˆç®—åœ–åƒé‡å¿ƒï¼Œå°‡æ•¸å­—å¹³ç§»è‡³ 28x28 ç•«å¸ƒçš„æ­£ä¸­å¤®ã€‚
    é€™æ˜¯ç‚ºäº†ç¬¦åˆ MNIST è¨“ç·´è³‡æ–™çš„æ ¼å¼ï¼Œèƒ½é¡¯è‘—æå‡è¾¨è­˜ç‡ã€‚
    """
    img = src.copy()
    m = cv2.moments(img, True)
    # è‹¥å½±åƒéç©º (m00 æ¥è¿‘ 0)ï¼Œç›´æ¥å›å‚³ç¸®æ”¾åœ–
    if m['m00'] < 0.1: return cv2.resize(img, (28, 28))
    
    # è¨ˆç®—é‡å¿ƒåº§æ¨™
    cX, cY = m['m10'] / m['m00'], m['m01'] / m['m00']
    # è¨ˆç®—å¹³ç§»é‡ (ç›®æ¨™ä¸­å¿ƒ 14.0)
    tX, tY = 14.0 - cX, 14.0 - cY
    
    M = np.float32([[1, 0, tX], [0, 1, tY]])
    return cv2.warpAffine(img, M, (28, 28), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)

def deskew(img):
    """
    é‡å°å‚¾æ–œçš„å­—é«”é€²è¡Œæ ¡æ­£ (Deskewing)ã€‚
    è¨ˆç®—å½±åƒçš„åæ…‹ (Skewness)ï¼Œä¸¦é€éä»¿å°„è®Šæ›å°‡å­—é«”æ‹‰ç›´ã€‚
    """
    m = cv2.moments(img)
    if abs(m['mu02']) < 1e-2: return img # é¿å…é™¤ä»¥é›¶
    skew = m['mu11'] / m['mu02']
    M = np.float32([[1, skew, -0.5 * img.shape[0] * skew], [0, 1, 0]])
    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)
    return img

def is_valid_content(img_bgr):
    """
    é€é HSV è‰²å½©ç©ºé–“æª¢æŸ¥ ROI æ˜¯å¦ç‚ºæœ‰æ•ˆå…§å®¹ã€‚
    éæ¿¾æ‰é«˜é£½å’Œåº¦(é€šå¸¸æ˜¯èƒŒæ™¯é›œç‰©)æˆ–ç‰¹å®šè‰²ç›¸çš„å€åŸŸã€‚
    """
    if img_bgr is None or img_bgr.size == 0: return False
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    mean_s = np.mean(hsv[:,:,1]) # å¹³å‡é£½å’Œåº¦
    if mean_s > 60: return False # é£½å’Œåº¦éé«˜é€šå¸¸ä¸æ˜¯é»‘ç™½æ–‡å­—
    if 30 < mean_s <= 60:
        mean_h = np.mean(hsv[:,:,0])
        if (mean_h < 25 or mean_h > 155): return False # éæ¿¾ç‰¹å®šé¡è‰²
    return True

# --------------------------------------------------------------------------------
# 3. åœ–ç‰‡ä¸Šå‚³æ¨¡å¼å°ˆç”¨å‡½å¼åº«
# --------------------------------------------------------------------------------
def detect_image_source(img_bgr):
    """
    åˆ¤æ–·åœ–ç‰‡ä¾†æºæ˜¯ã€Œæ•¸ä½æˆªåœ– (Digital)ã€é‚„æ˜¯ã€Œç¿»æ‹ç…§ç‰‡ (Photo)ã€ã€‚
    ä¾æ“šï¼šæ¥µç«¯é»‘èˆ‡æ¥µç«¯ç™½çš„åƒç´ æ¯”ä¾‹ã€‚æ•¸ä½åœ–é€šå¸¸é»‘ç™½åˆ†æ˜ã€‚
    """
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    extreme_pixels = np.sum((gray < 10) | (gray > 245))
    ratio = extreme_pixels / gray.size
    return "digital" if ratio > 0.5 else "photo"

def merge_overlapping_boxes(boxes):
    """
    åˆä½µé«˜åº¦é‡ç–Šçš„åµæ¸¬æ¡† (Bounding Boxes)ã€‚
    è§£æ±ºåŒä¸€å€‹æ•¸å­—è¢«åˆ‡æˆå…©åŠï¼Œæˆ–é‡è¤‡åµæ¸¬çš„å•é¡Œã€‚
    """
    if len(boxes) < 2: return boxes
    merged = []
    while len(boxes) > 0:
        curr = boxes.pop(0)
        x1, y1, w1, h1 = curr
        rx1, ry1 = x1 + w1, y1 + h1
        has_overlap = False
        i = 0
        while i < len(boxes):
            next_box = boxes[i]
            x2, y2, w2, h2 = next_box
            rx2, ry2 = x2 + w2, y2 + h2
            pad = 15 # å®¹è¨±çš„é‡ç–Šç·©è¡å€
            
            # åˆ¤æ–·æ˜¯å¦é‡ç–Š
            overlap = not ((rx1 + pad) < x2 or (x1 - pad) > rx2 or (ry1 + pad) < y2 or (y1 - pad) > ry2)
            if overlap:
                # è¨ˆç®—åˆä½µå¾Œçš„æ–°æ¡†
                new_x = min(x1, x2)
                new_y = min(y1, y2)
                new_w = max(rx1, rx2) - new_x
                new_h = max(ry1, ry2) - new_y
                curr = (new_x, new_y, new_w, new_h)
                x1, y1, w1, h1 = curr
                rx1, ry1 = new_x + new_w, new_y + new_h
                boxes.pop(i) # ç§»é™¤å·²è¢«åˆä½µçš„æ¡†
                has_overlap = True
            else:
                i += 1
        if has_overlap:
            boxes.insert(0, curr) # é‡æ–°æª¢æŸ¥åˆä½µå¾Œçš„æ¡†æ˜¯å¦é‚„è·Ÿåˆ¥äººé‡ç–Š
        else:
            merged.append(curr)
    return merged

def filter_small_boxes(boxes, img_height, img_width, source_type):
    """
    éæ¿¾å°ºå¯¸ä¸åˆç†çš„åµæ¸¬æ¡†ã€‚
    ä¾æ“šï¼šé¢ç©ä½”æ¯”ã€çµ•å°é«˜åº¦ã€é•·å¯¬æ¯” (Aspect Ratio)ã€‚
    """
    if not boxes: return []
    total_area = img_width * img_height
    
    # æ•¸ä½åœ–ç‰‡æ¨¡å¼ï¼šè¦å‰‡è¼ƒå¯¬é¬†
    if source_type == "digital":
        kept = [box for box in boxes if (box[2] * box[3]) < (total_area * 0.6) and box[3] > 5]
        return kept
    
    # ç…§ç‰‡æ¨¡å¼ï¼šè¦å‰‡è¼ƒåš´æ ¼ï¼Œéœ€è¨ˆç®—ä¸­ä½æ•¸é«˜åº¦
    abs_min_h = int(img_height * 0.02)
    valid_h = [b[3] for b in boxes if b[3] > abs_min_h]
    median_h = np.median(valid_h) if valid_h else 0
    kept_boxes = []
    
    for box in boxes:
        w, h = box[2], box[3]
        if (w * h) > (total_area * 0.6) or h < abs_min_h: continue # éå¤§æˆ–éå°
        
        aspect = w / float(h)
        # éæ–¼ç´°é•·ä¸”é«˜åº¦è¶³å¤ ï¼Œå¯èƒ½æ˜¯ "1"
        if aspect < 0.35 and median_h > 0 and h > (median_h * 0.35):
            kept_boxes.append(box); continue
        # é«˜åº¦é¡¯è‘—ä½æ–¼å¹³å‡ï¼Œè¦–ç‚ºé›œè¨Š
        if median_h > 0 and h < (median_h * 0.5): continue
        # ç…§ç‰‡æ¨¡å¼ä¸‹ï¼Œå¤ªçŸ®ä¸”å½¢ç‹€æ–¹æ­£çš„å¯èƒ½æ˜¯é›œé»
        if source_type == "photo" and h < 65 and 0.7 < aspect < 1.3: continue
        
        kept_boxes.append(box)
    return kept_boxes

def filter_low_contrast_boxes(boxes, gray_img):
    """
    éæ¿¾å°æ¯”åº¦éä½çš„å€åŸŸ (ä¾‹å¦‚é™°å½±)ã€‚
    è¨ˆç®—æ¡†å…§çš„ã€Œå¢¨æ°´é¡è‰²ã€èˆ‡ã€Œç´™å¼µèƒŒæ™¯è‰²ã€å·®ç•°ã€‚
    """
    if not boxes: return []
    flat = np.sort(gray_img.ravel())
    # ä¼°ç®—å¢¨æ°´é»‘ (å‰ 2% æ·±è‰²) èˆ‡ç´™å¼µç™½ (ä¸­ä½æ•¸)
    ink_black = np.mean(flat[:int(len(flat)*0.02)])
    paper_bg = np.median(flat)
    
    # è¨­å®šå°æ¯”é–¾å€¼ (èƒŒæ™¯èˆ‡å¢¨æ°´å·®çš„ 60%)
    threshold = paper_bg - ((paper_bg - ink_black) * 0.6)
    kept_boxes = []
    
    for box in boxes:
        x, y, w, h = box
        roi = gray_img[y:y+h, x:x+w]
        if roi.size == 0: continue
        roi_flat = np.sort(roi.ravel())
        # æª¢æŸ¥è©²å€åŸŸæœ€æ·±è‰²çš„éƒ¨åˆ†æ˜¯å¦è¶³å¤ é»‘
        if np.mean(roi_flat[:max(1, int(len(roi_flat)*0.1))]) <= threshold:
            kept_boxes.append(box)
    return kept_boxes

def preprocess_for_mnist(roi_binary):
    """
    å°‡äºŒå€¼åŒ–çš„ ROI è½‰æ›ç‚ºç¬¦åˆ MNIST æ¨¡å‹è¼¸å…¥çš„æ¨™æº–æ ¼å¼ã€‚
    æ­¥é©Ÿï¼š
    1. ä¿æŒé•·å¯¬æ¯”ç¸®æ”¾è‡³ 20x20ã€‚
    2. å¡«å……è‡³ 28x28 (Padding)ã€‚
    3. é‡å¿ƒç½®ä¸­ (Center by Moments)ã€‚
    """
    h, w = roi_binary.shape
    canvas = np.zeros((28, 28), dtype=np.uint8)
    
    # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹ï¼Œæœ€å¤§é‚Šé•·é™åˆ¶åœ¨ 20px
    scale = 20.0 / max(h, w)
    nh, nw = max(1, int(h * scale)), max(1, int(w * scale))
    roi_resized = cv2.resize(roi_binary, (nw, nh), interpolation=cv2.INTER_AREA)
    
    # è¨ˆç®—å¡«å……åç§»é‡
    y_off, x_off = (28 - nh) // 2, (28 - nw) // 2
    canvas[y_off:y_off+nh, x_off:x_off+nw] = roi_resized
    
    # ç¢ºä¿äºŒå€¼åŒ–æ¸…æ™°
    _, canvas = cv2.threshold(canvas, 10, 255, cv2.THRESH_BINARY)
    
    # ä½¿ç”¨å½±åƒçŸ©é€²è¡Œæœ€çµ‚æ ¡æ­£
    M = cv2.moments(canvas)
    if M["m00"] > 0:
        cx, cy = M["m10"] / M["m00"], M["m01"] / M["m00"]
        canvas = cv2.warpAffine(canvas, np.float32([[1, 0, 14-cx], [0, 1, 14-cy]]), (28, 28))
    
    # è¼•å¾®è†¨è„¹ä»¥å¢å¼·ç­†ç•«ç‰¹å¾µ
    return cv2.dilate(canvas, None, iterations=1)

def try_add_manual_box(click_x, click_y, binary_img, model):
    """
    è™•ç†ä½¿ç”¨è€…åœ¨åœ–ç‰‡ä¸Šé»æ“Šï¼Œæ‰‹å‹•æ–°å¢è¾¨è­˜æ¡†çš„é‚è¼¯ã€‚
    1. æª¢æŸ¥é»æ“Šåº§æ¨™æ˜¯å¦åœ¨ç¯„åœå…§ã€‚
    2. å°‹æ‰¾é»æ“Šé»æ‰€åœ¨çš„é€£é€šå€åŸŸ (Contour)ã€‚
    3. æå–è©²å€åŸŸä¸¦é€å…¥æ¨¡å‹é æ¸¬ã€‚
    """
    h, w = binary_img.shape
    if not (0 <= click_x < w and 0 <= click_y < h):
        return None, "âŒ é»æ“Šä½ç½®è¶…å‡ºç¯„åœ"
    
    # å°‹æ‰¾æ‰€æœ‰å¤–éƒ¨è¼ªå»“
    cnts, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    target_contour = None
    
    # æª¢æŸ¥é»æ“Šé»æ˜¯å¦åœ¨æŸå€‹è¼ªå»“å…§
    for c in cnts:
        if cv2.pointPolygonTest(c, (click_x, click_y), False) >= 0:
            target_contour = c
            break
    if target_contour is None:
        return None, "âš ï¸ æ²’é»åˆ°æ±è¥¿ (è«‹é»æ“Šæ–‡å­—ç­†è·¡çš„é»‘è‰²å€åŸŸ)"
    
    bx, by, bw, bh = cv2.boundingRect(target_contour)
    if bw < 5 or bh < 10: 
        return None, "âš ï¸ å€åŸŸå¤ªå°ï¼Œè¦–ç‚ºé›œè¨Š"
    
    # é€²è¡Œé æ¸¬
    roi = binary_img[by:by+bh, bx:bx+bw]
    roi_processed = preprocess_for_mnist(roi)
    input_data = roi_processed.reshape(1, 28, 28, 1).astype('float32') / 255.0
    pred = model.predict(input_data, verbose=0)[0]
    res_id = np.argmax(pred)
    conf = float(pred[res_id])
    
    return {
        "rect": (bx, by, bw, bh),
        "label": int(res_id),
        "conf": conf
    }, f"âœ… æ‰‹å‹•åŠ å…¥æˆåŠŸï¼šæ•¸å­— {res_id}"

# --------------------------------------------------------------------------------
# 4. æ‰‹å¯«æ¿æ¨¡å¼å°ˆç”¨ï¼šæ™ºæ…§åˆä½µé‚è¼¯
# --------------------------------------------------------------------------------
def get_edge_distance(r1, r2):
    """è¨ˆç®—å…©å€‹çŸ©å½¢é‚Šç·£çš„æœ€çŸ­è·é›¢"""
    x1, y1, w1, h1 = r1
    x2, y2, w2, h2 = r2
    rx1, ry1 = x1 + w1, y1 + h1
    rx2, ry2 = x2 + w2, y2 + h2
    dx = max(0, max(x1 - rx2, x2 - rx1))
    dy = max(0, max(y1 - ry2, y2 - ry1))
    return np.sqrt(dx*dx + dy*dy)

def merge_boxes_logic(contours, merge_dist_limit, time_limit):
    """
    å‹•æ…‹ç­†è·¡åˆä½µé‚è¼¯ã€‚
    çµåˆã€Œç©ºé–“è·é›¢ã€èˆ‡ã€Œæ™‚é–“å·®ã€ï¼Œå°‡æ–·é–‹çš„ç­†ç•« (å¦‚å¯« '5' çš„å…©ç­†) åˆä½µç‚ºåŒä¸€ç‰©ä»¶ã€‚
    """
    if 'box_cache' not in st.session_state:
        st.session_state['box_cache'] = []
    
    current_time = time.time()
    raw_boxes = [cv2.boundingRect(cnt) for cnt in contours]
    current_boxes_with_time = []
    
    # æ­¥é©Ÿ 1: å°‡ç•¶å‰è¼ªå»“èˆ‡æ­·å²å¿«å–é€²è¡ŒåŒ¹é…ï¼Œä»¥ç¹¼æ‰¿æ™‚é–“æˆ³è¨˜
    for r_new in raw_boxes:
        assigned_time = current_time
        best_overlap = 0
        for old_item in st.session_state['box_cache']:
            ox, oy, ow, oh = old_item['rect']
            # è¨ˆç®—äº¤é›†
            ix = max(r_new[0], ox)
            iy = max(r_new[1], oy)
            iw = min(r_new[0]+r_new[2], ox+ow) - ix
            ih = min(r_new[1]+r_new[3], oy+oh) - iy
            if iw > 0 and ih > 0:
                overlap = iw * ih
                if overlap > best_overlap:
                    best_overlap = overlap
                    assigned_time = old_item['time'] # ç¹¼æ‰¿èˆŠæ™‚é–“
        current_boxes_with_time.append({'rect': r_new, 'time': assigned_time})

    # æ­¥é©Ÿ 2: è¿­ä»£åˆä½µæ¥è¿‘ä¸”æ™‚é–“ç›¸è¿‘çš„æ¡†
    has_merged = True
    while has_merged:
        has_merged = False
        new_list = []
        skip_indices = set()
        for i in range(len(current_boxes_with_time)):
            if i in skip_indices: continue
            merged_rect = current_boxes_with_time[i]['rect']
            merged_time = current_boxes_with_time[i]['time']
            for j in range(i + 1, len(current_boxes_with_time)):
                if j in skip_indices: continue
                b1 = current_boxes_with_time[i]
                b2 = current_boxes_with_time[j]
                
                dist = get_edge_distance(merged_rect, b2['rect'])
                time_diff = abs(merged_time - b2['time'])
                
                # è‹¥è·é›¢å¤ è¿‘ä¸”æ˜¯è¿‘æœŸå¯«ä¸‹çš„ï¼Œå‰‡åˆä½µ
                if dist < merge_dist_limit and time_diff < time_limit:
                    x1, y1 = merged_rect[0], merged_rect[1]
                    x2, y2 = merged_rect[0] + merged_rect[2], merged_rect[1] + merged_rect[3]
                    bx1, by1 = b2['rect'][0], b2['rect'][1]
                    bx2, by2 = b2['rect'][0] + b2['rect'][2], b2['rect'][1] + b2['rect'][3]
                    nx1, ny1 = min(x1, bx1), min(y1, by1)
                    nx2, ny2 = max(x2, bx2), max(y2, by2)
                    merged_rect = (nx1, ny1, nx2 - nx1, ny2 - ny1)
                    merged_time = max(merged_time, b2['time'])
                    skip_indices.add(j)
                    has_merged = True
            new_list.append({'rect': merged_rect, 'time': merged_time})
        if has_merged: current_boxes_with_time = new_list
        else: break

    st.session_state['box_cache'] = current_boxes_with_time
    
    # è¼¸å‡ºæœ€çµ‚çµæœ
    final_output = []
    for item in current_boxes_with_time:
        x, y, w, h = item['rect']
        cx, cy = x + w//2, y + h//2
        final_output.append({'rect': (x,y,w,h), 'center': (cx, cy)})
    return final_output

def update_tracker_from_boxes(box_items):
    """
    ç‰©ä»¶è¿½è¹¤ (Object Tracking)ã€‚
    ç‚ºæ¯å€‹è¾¨è­˜å‡ºçš„æ•¸å­—åˆ†é…ä¸€å€‹å”¯ä¸€çš„ IDï¼Œç¢ºä¿ç•«é¢æ›´æ–°æ™‚ ID ä¸æœƒäº‚è·³ã€‚
    """
    current_items = box_items
    used_current_indices = set()
    new_tracker_state = {}
    
    # å˜—è©¦å°‡æ–°åµæ¸¬åˆ°çš„ç‰©ä»¶èˆ‡èˆŠ ID åŒ¹é… (åŸºæ–¼ä¸­å¿ƒé»è·é›¢)
    if 'tracker_state' in st.session_state:
        for old_id, old_center in st.session_state['tracker_state'].items():
            min_dist = 9999
            match_idx = -1
            for i, item in enumerate(current_items):
                if i in used_current_indices: continue
                dist = np.hypot(item['center'][0]-old_center[0], item['center'][1]-old_center[1])
                if dist < 50 and dist < min_dist:
                    min_dist = dist
                    match_idx = i
            if match_idx != -1:
                current_items[match_idx]['id'] = old_id
                used_current_indices.add(match_idx)
                new_tracker_state[old_id] = current_items[match_idx]['center']
    
    # ç‚ºæœªåŒ¹é…çš„æ–°ç‰©ä»¶åˆ†é…æ–° ID
    for i, item in enumerate(current_items):
        if 'id' not in item:
            item['id'] = st.session_state['next_id']
            st.session_state['next_id'] += 1
            new_tracker_state[item['id']] = item['center']
            
    st.session_state['tracker_state'] = new_tracker_state
    current_items.sort(key=lambda x: x['id'])
    return current_items

# --------------------------------------------------------------------------------
# 5. UI ä»‹é¢è¼”åŠ©å·¥å…·
# --------------------------------------------------------------------------------
def get_responsive_layout(ratios):
    """
    éŸ¿æ‡‰å¼ä½ˆå±€ç”Ÿæˆå™¨ã€‚
    è‹¥ç‚ºæ‰‹æ©Ÿæ¨¡å¼ï¼Œå¼·åˆ¶ä½¿ç”¨å‚ç›´å †ç–Š (Container)ï¼›è‹¥ç‚ºé›»è…¦æ¨¡å¼ï¼Œä½¿ç”¨æ°´å¹³æ¬„ä½ (Columns)ã€‚
    """
    if st.session_state.get('last_device_mode') and "æ‰‹æ©Ÿ" in st.session_state['last_device_mode']:
        return [st.container() for _ in ratios]
    else:
        return st.columns(ratios)

def get_bar_html(confidence, is_uncertain=False):
    """ç”Ÿæˆ HTML æ ¼å¼çš„ä¿¡å¿ƒåº¦èƒ½é‡æ¢ (Progress Bar)ã€‚"""
    percent = min(int(confidence * 100), 100)
    # é¡è‰²é‚è¼¯ï¼šä¸ç¢ºå®š=æ©˜è‰², é«˜ä¿¡å¿ƒ=ç¶ è‰², æ™®é€š=é»ƒè‰²
    color = "#ff9f43" if is_uncertain else "#2ecc71" if confidence > 0.95 else "#f1c40f"
    return f"""<div style="display:flex;align-items:center;margin-top:4px;"><div style="width:50%;height:8px;background:#444;border-radius:4px;overflow:hidden;"><div style="width:{percent}%;height:100%;background:{color};"></div></div><span style="margin-left:8px;font-size:0.8em;color:{color};">{percent}%</span></div>"""

# --------------------------------------------------------------------------------
# 6. WebRTC å½±åƒè™•ç†æ ¸å¿ƒ (é¡é ­æ¨¡å¼ç”¨)
# --------------------------------------------------------------------------------
# --------------------------------------------------------------------------------
# 6. WebRTC å½±åƒè™•ç†æ ¸å¿ƒ (é¡é ­æ¨¡å¼ç”¨) - å·²ä¿®æ­£æš–èº«èˆ‡é˜²èª¤è§¸é‚è¼¯
# --------------------------------------------------------------------------------
class HandwriteProcessor(VideoProcessorBase):
    def __init__(self):
        self.model = model
        self.knn = knn_model
        self.last_boxes = []        # ç”¨æ–¼è¨ˆç®—ç•«é¢ç©©å®šåº¦çš„ä¸Šä¸€å¹€æ¡†ä½ç½®
        self.stability_start_time = None # ç•«é¢é–‹å§‹ç©©å®šçš„æ™‚é–“é»
        self.frozen = False         # æ˜¯å¦è§¸ç™¼æŠ“æ‹å‡çµ
        self.frozen_frame = None    # å‡çµæ™‚çš„ç•«é¢
        self.detected_count = 0     # åµæ¸¬æ•¸é‡
        self.ui_results = []        # å‚³å› UI é¡¯ç¤ºçš„æ–‡å­—çµæœ
        self.frame_counter = 0      # å¹€æ•¸è¨ˆæ•¸å™¨
        self.skip_rate = 4          # æ¯ N å¹€è™•ç†ä¸€æ¬¡ (ç¯€çœæ•ˆèƒ½)
        self.cached_rois = []       # å¿«å–çš„ç¹ªåœ–è³‡è¨Š (ç”¨æ–¼è·³éçš„å¹€)
        
        # [æ–°å¢] æš–èº«æ©Ÿåˆ¶ï¼šé¿å…é–‹æ©Ÿç¬é–“èª¤åˆ¤
        self.session_start_time = time.time()
        self.warmup_duration = 1.5  # æš–èº«æ™‚é–“ (ç§’)

    def resume(self):
        """è§£é™¤å‡çµï¼Œæ¢å¾©å³æ™‚æ”å½±"""
        self.frozen = False
        self.stability_start_time = None
        self.last_boxes = []
        self.ui_results = [] 
        self.frame_counter = 0
        # [æ–°å¢] é‡ç½®æš–èº«è¨ˆæ™‚
        self.session_start_time = time.time()

    def recv(self, frame):
        """
        WebRTC çš„æ ¸å¿ƒå›èª¿å‡½å¼ï¼Œè™•ç†æ¯ä¸€å¹€å½±åƒã€‚
        åŒ…å«ï¼šROI è£åˆ‡ã€å‰è™•ç†ã€æ¨¡å‹é æ¸¬ã€ç©©å®šåº¦åµæ¸¬ã€ç¹ªåœ–ã€‚
        """
        img = frame.to_ndarray(format="bgr24")
        
        # [é‡è¦ä¿®æ­£] åœ¨å‡½å¼æœ€é–‹é ­è¨ˆç®—æš–èº«ç‹€æ…‹ï¼Œé¿å…è®Šæ•¸æœªå®šç¾©éŒ¯èª¤
        # é˜²å‘†æª¢æŸ¥ï¼šè‹¥å› ç†±é‡è¼‰å°è‡´è®Šæ•¸éºå¤±ï¼Œé‡æ–°åˆå§‹åŒ–
        if not hasattr(self, 'session_start_time') or self.session_start_time is None:
            self.session_start_time = time.time()
            self.warmup_duration = 1.5
            
        is_warming_up = (time.time() - self.session_start_time) < self.warmup_duration

        # è‹¥å·²å‡çµï¼ŒæŒçºŒå›å‚³åŒä¸€å¼µéœæ…‹åœ–
        if self.frozen and self.frozen_frame is not None:
            return av.VideoFrame.from_ndarray(self.frozen_frame, format="bgr24")
        
        display_img = img.copy()
        h_f, w_f = img.shape[:2]
        
        # å®šç¾©æ„Ÿèˆˆè¶£å€åŸŸ (ROI)ï¼Œé¿å…é‚Šç·£é›œè¨Š
        roi_rect = [ROI_MARGIN_X, ROI_MARGIN_Y, w_f - 2*ROI_MARGIN_X, h_f - 2*ROI_MARGIN_Y]
        
        # ç¹ªè£½ ROI æ¡† (æ ¹æ“šæš–èº«ç‹€æ…‹è®Šè‰²ï¼šç´…=æœªæº–å‚™å¥½, è—=æ­£å¸¸)
        roi_color = (0, 0, 255) if is_warming_up else (255, 0, 0)
        cv2.rectangle(display_img, (roi_rect[0], roi_rect[1]), (roi_rect[0]+roi_rect[2], roi_rect[1]+roi_rect[3]), roi_color, 2)

        # æ•ˆèƒ½å„ªåŒ–ï¼šè·³å¹€è™•ç†
        self.frame_counter += 1
        if not (self.frame_counter % self.skip_rate == 0):
            # åœ¨è·³éçš„å¹€ä¸Šç¹ªè£½ä¸Šä¸€æ¬¡çš„å¿«å–çµæœï¼Œé¿å…é–ƒçˆ
            if len(self.cached_rois) > 0:
                for (dx, dy, dw, dh, txt, box_color, box_thick) in self.cached_rois:
                    cv2.rectangle(display_img, (dx, dy), (dx+dw, dy+dh), box_color, box_thick)
                    cv2.putText(display_img, txt, (dx, dy-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            # è£œä¸Šæš–èº«æç¤ºå­— (è·³å¹€æ™‚ä¹Ÿè¦é¡¯ç¤º)
            if is_warming_up:
                cv2.putText(display_img, "Initializing...", (20, h_f - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            return av.VideoFrame.from_ndarray(display_img, format="bgr24")
        
        # æå– ROI ä¸¦é€²è¡Œå‰è™•ç†
        roi_img = img[roi_rect[1]:roi_rect[1]+roi_rect[3], roi_rect[0]:roi_rect[0]+roi_rect[2]]
        if roi_img.size == 0: return av.VideoFrame.from_ndarray(display_img, format="bgr24")

        gray = cv2.cvtColor(roi_img, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 45, 18)
        binary_proc = cv2.dilate(thresh, None, iterations=2)
        
        # å°‹æ‰¾è¼ªå»“
        contours, hierarchy = cv2.findContours(binary_proc, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
        valid_boxes = []
        if hierarchy is not None:
            for i, cnt in enumerate(contours):
                # åƒ…ä¿ç•™å¤–å±¤è¼ªå»“ä¸”é¢ç©è¶³å¤ è€…
                if hierarchy[0][i][3] == -1:
                    area = cv2.contourArea(cnt)
                    if area > MIN_AREA:
                        x, y, w, h = cv2.boundingRect(cnt)
                        # æª¢æŸ¥æ˜¯å¦æœ‰å­è¼ªå»“ (å³å­”æ´)
                        has_hole = hierarchy[0][i][2] != -1
                        valid_boxes.append({"box": (x, y, w, h), "has_hole": has_hole, "aspect_ratio": w / float(h)})
        
        valid_boxes = sorted(valid_boxes, key=lambda b: b["box"][0])
        batch_rois, batch_info, raw_boxes_for_stability = [], [], []
        self.cached_rois = []

        # æº–å‚™æ‰¹é‡é æ¸¬è³‡æ–™
        for item in valid_boxes:
            x, y, w, h = item["box"]
            rx, ry = x + roi_rect[0], y + roi_rect[1]
            
            if x < 5 or y < 5 or (x+w) > binary_proc.shape[1]-5 or (y+h) > binary_proc.shape[0]-5: continue
            if h < MIN_HEIGHT: continue
            
            roi_color_check = display_img[ry:ry+h, rx:rx+w]
            if not is_valid_content(roi_color_check): continue
            
            raw_boxes_for_stability.append(item)
            
            roi_single = deskew(binary_proc[y:y+h, x:x+w])
            side = max(w, h)
            padding = int(side * 0.2)
            container_size = side + padding * 2
            container = np.zeros((container_size, container_size), dtype=np.uint8)
            offset_y = (container_size - h) // 2
            offset_x = (container_size - w) // 2
            roi_single = cv2.resize(roi_single, (w, h)) 
            container[offset_y:offset_y+h, offset_x:offset_x+w] = roi_single
            roi_resized = cv2.resize(container, (28, 28), interpolation=cv2.INTER_AREA)
            roi_norm = roi_resized.astype('float32') / 255.0
            
            batch_rois.append(roi_norm.reshape(28, 28, 1))
            batch_info.append({"coords": (rx, ry, w, h), "has_hole": item["has_hole"], "aspect": item["aspect_ratio"], "flat_input": roi_norm.reshape(1, 784)})
            
        detected_count = 0
        detected_something = False
        current_frame_text_results = []
        valid_ui_counter = 1

        # åŸ·è¡Œæ‰¹é‡é æ¸¬
        if len(batch_rois) > 0 and self.model is not None:
            detected_something = True
            try:
                batch_input = np.stack(batch_rois)
                predictions = self.model.predict(batch_input, verbose=0)
                
                for i, pred in enumerate(predictions):
                    top_indices = pred.argsort()[-3:][::-1]
                    res_id = top_indices[0]
                    confidence = pred[res_id]
                    
                    if confidence < CONFIDENCE_THRESHOLD: continue 

                    info = batch_info[i]
                    rx, ry, w, h = info["coords"]
                    aspect = info["aspect"]
                    has_hole = info["has_hole"]
                    
                    # è¦å‰‡åº«ä¿®æ­£
                    if res_id == 1 and aspect > 0.6: res_id = 7
                    elif res_id == 7 and aspect < 0.25: res_id = 1
                    if res_id == 7 and has_hole: res_id = 9
                    if res_id == 9 and not has_hole and confidence < 0.95: res_id = 7
                    if res_id == 0 and aspect < 0.5: res_id = 1
                    
                    final_label_str = str(res_id)
                    verify_msg = ""
                    
                    # KNN é›™é‡é©—è­‰
                    is_knned = False
                    if self.knn is not None and KNN_VERIFY_RANGE[0] <= confidence <= KNN_VERIFY_RANGE[1]:
                        try:
                            knn_pred = self.knn.predict(info["flat_input"])[0]
                            if knn_pred != res_id:
                                final_label_str = str(res_id)
                                verify_msg = f" âš ï¸ KNN: {knn_pred}"
                                is_knned = True
                        except: pass
                    
                    # [ä¿®æ”¹] æ ¹æ“šæš–èº«ç‹€æ…‹æ±ºå®šæ¡†çš„é¡è‰² (è¦–è¦ºå›é¥‹)
                    if is_warming_up:
                        box_color = (0, 0, 255)   # ç´…è‰²ï¼šæš–èº«ä¸­ï¼Œæœªé–å®š
                        box_thickness = 1         # ç´°ç·š
                    elif is_knned:
                        box_color = (0, 165, 255) # æ©˜è‰²ï¼šKNN è­¦å‘Š
                        box_thickness = 2
                    else:
                        box_color = (0, 255, 0)   # ç¶ è‰²ï¼šæº–å‚™å®Œæˆ
                        box_thickness = 2

                    # ç¹ªè£½çµæœæ¡†èˆ‡æ¨™ç±¤
                    draw_x = rx + SHRINK_PX
                    draw_y = ry + SHRINK_PX
                    draw_w = max(1, w - (SHRINK_PX * 2))
                    draw_h = max(1, h - (SHRINK_PX * 2))
                    cv2.rectangle(display_img, (draw_x, draw_y), (draw_x+draw_w, draw_y+draw_h), box_color, box_thickness)
                    text_label = f"#{valid_ui_counter}"
                    cv2.putText(display_img, text_label, (rx, ry-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                    
                    # å„²å­˜ç¹ªåœ–è³‡è¨Šä¾›è·³å¹€ä½¿ç”¨ (å¤šå­˜äº† box_thickness)
                    self.cached_rois.append((draw_x, draw_y, draw_w, draw_h, text_label, box_color, box_thickness))
                    
                    info_text = f"**#{valid_ui_counter}**: æ•¸å­— `{res_id}` (ä¿¡å¿ƒ: {int(confidence*100)}%){verify_msg}"
                    current_frame_text_results.append(info_text)
                    detected_count += 1
                    valid_ui_counter += 1
            except: pass

        self.detected_count = detected_count
        if detected_something: self.ui_results = current_frame_text_results

        # --- ç©©å®šåº¦åµæ¸¬èˆ‡è‡ªå‹•æŠ“æ‹é‚è¼¯ ---
        if len(raw_boxes_for_stability) == 0:
            self.stability_start_time = None
        elif len(self.last_boxes) == 0:
            self.last_boxes = raw_boxes_for_stability
            self.stability_start_time = time.time()
        else:
            total_movement = 0
            for curr_box in raw_boxes_for_stability:
                c_x, c_y, _, _ = curr_box["box"]
                min_dist = 99999
                for last_box in self.last_boxes:
                    l_x, l_y, _, _ = last_box["box"]
                    dist = abs(c_x - l_x) + abs(c_y - l_y)
                    if dist < min_dist: min_dist = dist
                if min_dist < 30: total_movement += min_dist
                else: total_movement += 20 
            
            count_diff = abs(len(raw_boxes_for_stability) - len(self.last_boxes))
            total_movement += count_diff * 30 
            self.last_boxes = raw_boxes_for_stability

            # [ä¿®æ”¹] è‹¥ç§»å‹•é‡ä½æ–¼é–¥å€¼ï¼Œä¸”ã€Œä¸åœ¨æš–èº«æœŸã€ï¼Œæ‰é–‹å§‹é›†æ°£
            if total_movement < MOVEMENT_THRESHOLD and not is_warming_up:
                if self.stability_start_time is None: self.stability_start_time = time.time()
                elapsed = time.time() - self.stability_start_time
                progress = min(elapsed / STABILITY_DURATION, 1.0)
                
                # ç¹ªè£½åº•éƒ¨é€²åº¦æ¢
                bar_y = h_f - 20 
                bar_w = int(600 * progress)
                color = (0, 255, 255) if progress < 1.0 else (0, 255, 0)
                cv2.rectangle(display_img, (20, bar_y - 15), (20 + bar_w, bar_y), color, -1)
                cv2.rectangle(display_img, (20, bar_y - 15), (w_f - 20, bar_y), (255, 255, 255), 2)
                
                # é›†æ°£å®Œæˆï¼Œè§¸ç™¼å‡çµ
                if elapsed >= STABILITY_DURATION and detected_something:
                    self.frozen = True
                    self.frozen_frame = display_img.copy()
            else:
                self.stability_start_time = time.time() # æ™ƒå‹•å¤ªå¤§æˆ–æš–èº«ä¸­ï¼Œé‡ç½®è¨ˆæ™‚
                
                # [æ–°å¢] æš–èº«ä¸­çš„æ–‡å­—æç¤º
                if is_warming_up:
                    cv2.putText(display_img, "Initializing...", (20, h_f - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                
        return av.VideoFrame.from_ndarray(display_img, format="bgr24")

# --------------------------------------------------------------------------------
# 7. Streamlit ä»‹é¢èˆ‡å…¥å£é–˜é–€ (Gatekeeper)
# --------------------------------------------------------------------------------
st.set_page_config(page_title="æ‰‹å¯«è¾¨è­˜", page_icon="ğŸ“", layout="wide")

# åˆå§‹åŒ– Session State (ç‹€æ…‹ç®¡ç†)ï¼Œç¢ºä¿è®Šæ•¸åœ¨é é¢åˆ·æ–°å¾Œä»ä¿ç•™
if 'stats' not in st.session_state: st.session_state['stats'] = {'camera': {'total': 0, 'correct': 0}, 'handwriting': {'total': 0, 'correct': 0}, 'upload': {'total': 0, 'correct': 0}}
if 'history' not in st.session_state: st.session_state['history'] = {'camera': [], 'handwriting': [], 'upload': []} 
if 'tracker_state' not in st.session_state: st.session_state['tracker_state'] = {}
if 'next_id' not in st.session_state: st.session_state['next_id'] = 1
if 'hw_display_list' not in st.session_state: st.session_state['hw_display_list'] = []
if 'hw_result_img' not in st.session_state: st.session_state['hw_result_img'] = None
if 'hw_result_count' not in st.session_state: st.session_state['hw_result_count'] = 0
if 'box_cache' not in st.session_state: st.session_state['box_cache'] = [] 
if 'upload_display_list' not in st.session_state: st.session_state['upload_display_list'] = []
if 'upload_result_img' not in st.session_state: st.session_state['upload_result_img'] = None
if 'upload_result_count' not in st.session_state: st.session_state['upload_result_count'] = 0
if 'last_uploaded_file_id' not in st.session_state: st.session_state['last_uploaded_file_id'] = None
if 'ignored_boxes' not in st.session_state: st.session_state['ignored_boxes'] = set()
if 'manual_boxes' not in st.session_state: st.session_state['manual_boxes'] = []
if 'input_key' not in st.session_state: st.session_state['input_key'] = 0

# --- è£ç½®é¸æ“‡é–˜é–€ ---
DEVICE_PC = "ğŸ–¥ï¸ é›»è…¦ç‰ˆ (ä¸¦æ’ä½ˆå±€)"
DEVICE_MOBILE = "ğŸ“± æ‰‹æ©Ÿç‰ˆ (å‚ç›´ä½ˆå±€)"

# é¦–æ¬¡é€²å…¥æ™‚å¼·åˆ¶é¸æ“‡è£ç½®é¡å‹
if 'last_device_mode' not in st.session_state:
    st.markdown("<br><br><br>", unsafe_allow_html=True)
    st.markdown("<h1 style='text-align: center;'>ğŸ‘‹ æ­¡è¿ä½¿ç”¨æ‰‹å¯«æ•¸å­—è¾¨è­˜ç³»çµ±</h1>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: center; color: gray;'>è«‹é¸æ“‡æ‚¨çš„æ“ä½œè£ç½®ä»¥æœ€ä½³åŒ–ä»‹é¢</h3>", unsafe_allow_html=True)
    st.write("")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        c_pc, c_mo = st.columns(2)
        with c_pc:
            if st.button("ğŸ–¥ï¸ é›»è…¦ / å¹³æ¿", use_container_width=True, type="primary"):
                st.session_state['last_device_mode'] = DEVICE_PC
                st.rerun()
        with c_mo:
            if st.button("ğŸ“± æ‰‹æ©Ÿ", use_container_width=True, type="primary"):
                st.session_state['last_device_mode'] = DEVICE_MOBILE
                st.rerun()
    st.stop() # åœæ­¢åŸ·è¡Œä¸‹æ–¹ä»£ç¢¼ï¼Œç›´åˆ°é¸æ“‡å®Œæˆ

device_mode = st.session_state['last_device_mode']
is_mobile = "æ‰‹æ©Ÿ" in device_mode

# --- å´é‚Šæ¬„æ§åˆ¶å° ---
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    st.markdown("### ğŸ“± é¡¯ç¤ºè¨­å®š")
    st.info(f"ç›®å‰æ¨¡å¼ï¼š{device_mode}")
    if st.button("ğŸ”„ é‡æ–°é¸æ“‡è£ç½®"):
        del st.session_state['last_device_mode']
        # é‡ç½®æ‰€æœ‰ç›¸é—œç‹€æ…‹
        st.session_state['hw_result_img'] = None
        st.session_state['hw_display_list'] = []
        st.session_state['hw_result_count'] = 0
        st.session_state['tracker_state'] = {}
        st.session_state['box_cache'] = []
        st.session_state['canvas_key'] = f"canvas_{time.time()}"
        st.rerun()
    st.divider()
    app_mode = st.radio("æ¨¡å¼é¸æ“‡", ["ğŸ“· é¡é ­æ¨¡å¼ (Live)", "ğŸ¨ æ‰‹å¯«æ¿æ¨¡å¼", "ğŸ“ åœ–ç‰‡ä¸Šå‚³æ¨¡å¼"], index=1)
    st.divider()
    
    # --- æˆç¸¾çµ±è¨ˆå€å¡Š ---
    # 1. é¡é ­æˆç¸¾
    st.markdown("### ğŸ“· é¡é ­æˆç¸¾")
    c_total = st.session_state['stats']['camera']['total']
    c_correct = st.session_state['stats']['camera']['correct']
    c_acc = (c_correct / c_total * 100) if c_total > 0 else 0.0
    col_c1, col_c2 = st.columns(2)
    with col_c1: st.metric("ç¸½æ•¸", c_total)
    with col_c2: st.metric("æ­£ç¢º", c_correct)
    st.metric("é¡é ­æº–ç¢ºç‡", f"{c_acc:.1f}%")
    
    col_undo_c, col_reset_c = st.columns(2)
    with col_undo_c:
        if st.button("â†©ï¸ å¾©åŸ", key="undo_cam"):
            if st.session_state['history']['camera']:
                last_entry = st.session_state['history']['camera'].pop()
                st.session_state['stats']['camera']['total'] -= last_entry['total']
                st.session_state['stats']['camera']['correct'] -= last_entry['correct']
                st.rerun()
    with col_reset_c:
        if st.button("ğŸ—‘ï¸ é‡ç½®", key="reset_cam"):
            st.session_state['stats']['camera'] = {'total': 0, 'correct': 0}
            st.session_state['history']['camera'] = []
            st.rerun()

    st.divider()
    # 2. æ‰‹å¯«æˆç¸¾
    st.markdown("### ğŸ¨ æ‰‹å¯«æˆç¸¾")
    h_total = st.session_state['stats']['handwriting']['total']
    h_correct = st.session_state['stats']['handwriting']['correct']
    h_acc = (h_correct / h_total * 100) if h_total > 0 else 0.0
    col_h1, col_h2 = st.columns(2)
    with col_h1: st.metric("ç¸½æ•¸", h_total)
    with col_h2: st.metric("æ­£ç¢º", h_correct)
    st.metric("æ‰‹å¯«æº–ç¢ºç‡", f"{h_acc:.1f}%")

    col_undo_h, col_reset_h = st.columns(2)
    with col_undo_h:
        if st.button("â†©ï¸ å¾©åŸ", key="undo_hw"):
            if st.session_state['history']['handwriting']:
                last_entry = st.session_state['history']['handwriting'].pop()
                st.session_state['stats']['handwriting']['total'] -= last_entry['total']
                st.session_state['stats']['handwriting']['correct'] -= last_entry['correct']
                st.rerun()
    with col_reset_h:
        if st.button("ğŸ—‘ï¸ é‡ç½®", key="reset_hw"):
            st.session_state['stats']['handwriting'] = {'total': 0, 'correct': 0}
            st.session_state['history']['handwriting'] = []
            st.session_state['tracker_state'] = {}
            st.session_state['next_id'] = 1
            st.rerun()

    st.divider()
    # 3. ä¸Šå‚³æˆç¸¾
    st.markdown("### ğŸ“ ä¸Šå‚³æˆç¸¾")
    u_total = st.session_state['stats']['upload']['total']
    u_correct = st.session_state['stats']['upload']['correct']
    u_acc = (u_correct / u_total * 100) if u_total > 0 else 0.0
    col_u1, col_u2 = st.columns(2)
    with col_u1: st.metric("ç¸½æ•¸", u_total)
    with col_u2: st.metric("æ­£ç¢º", u_correct)
    st.metric("ä¸Šå‚³æº–ç¢ºç‡", f"{u_acc:.1f}%")

    col_undo_u, col_reset_u = st.columns(2)
    with col_undo_u:
        if st.button("â†©ï¸ å¾©åŸ", key="undo_up"):
            if st.session_state['history']['upload']:
                last_entry = st.session_state['history']['upload'].pop()
                st.session_state['stats']['upload']['total'] -= last_entry['total']
                st.session_state['stats']['upload']['correct'] -= last_entry['correct']
                st.rerun()
    with col_reset_u:
        if st.button("ğŸ—‘ï¸ é‡ç½®", key="reset_up"):
            st.session_state['stats']['upload'] = {'total': 0, 'correct': 0}
            st.session_state['history']['upload'] = []
            st.session_state['upload_display_list'] = []
            st.session_state['upload_result_img'] = None
            st.session_state['upload_result_count'] = 0
            st.rerun()

st.title("ğŸ“ æ‰‹å¯«æ•¸å­—è¾¨è­˜ç³»çµ±")

if model is None: st.error("âŒ æ‰¾ä¸åˆ°æ¨¡å‹ï¼"); st.stop()

# ==============================================================================
# æ¨¡å¼ A: é¡é ­æ¨¡å¼ (Live)
# ==============================================================================
if app_mode == "ğŸ“· é¡é ­æ¨¡å¼ (Live)":
    with st.expander("ğŸ“– é¡é ­æ¨¡å¼æŒ‡å—(è«‹é»é–‹)", expanded=False):
        st.markdown("""
        1. **å°æº–é¡é ­**ï¼šè«‹å°‡å¯«æœ‰æ•¸å­—çš„ç´™å¼µå¹³ç©©ç½®æ–¼é¡é ­å‰ã€‚
        2. **ä¿æŒç©©å®š**ï¼šç•¶ç•«é¢åµæ¸¬åˆ°æ•¸å­—ä¸”ç•«é¢ç©©å®šæ™‚ï¼Œä¸‹æ–¹ **è—æ¢** æœƒé–‹å§‹é›†æ°£ã€‚
        3. **è‡ªå‹•æŠ“æ‹**ï¼šé›†æ°£æ»¿å¾Œç•«é¢æœƒè‡ªå‹• **å‡çµ (Captured)** ä¸¦é¡¯ç¤ºè¾¨è­˜çµæœã€‚
        4. **ç¢ºèªæˆç¸¾**ï¼šç¢ºèªç„¡èª¤å¾Œï¼Œæ–¼å³å´è¼¸å…¥æ­£ç¢ºæ•¸é‡ä¸¦ä¸Šå‚³æˆç¸¾ã€‚
        5. å¦‚æœæ²’åµæ¸¬åˆ°å¯èƒ½æ˜¯å…‰ç·šå•é¡Œæˆ–ç­†è·¡å¤ªç´°
        6. ç•«é¢ä¸Šé¡¯ç¤ºçš„æ˜¯åºè™Ÿï¼Œæƒ³çŸ¥é“åˆ¤æ–·çµæœè«‹æŒ‰ğŸ“‹ é¡¯ç¤ºè©³æƒ…
        """)
    
    # ä½ˆå±€é…ç½®
    layout_containers = get_responsive_layout([2, 1])
    col_cam = layout_containers[0]
    col_data = layout_containers[1]

    with col_cam:
        # å•Ÿå‹• WebRTC ä¸²æµ
        ctx = webrtc_streamer(
            key="handwrite-live",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=HandwriteProcessor,
            media_stream_constraints={"video": {"width": 1280, "height": 720}, "audio": False},
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            async_processing=True,
        )

    with col_data:
        st.markdown("### ğŸ“Š è©³ç´°æ•¸æ“š")
        st.caption("è«‹ç­‰å¾…ç•«é¢å‡ºç¾ Captured å¾Œï¼ŒæŒ‰ä¸‹æ–¹æŒ‰éˆ•æ›´æ–°æ•¸æ“š")
        
        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            if st.button("ğŸ“‹ é¡¯ç¤ºè©³æƒ…", type="secondary", use_container_width=True):
                if ctx.video_processor and ctx.video_processor.frozen:
                    results = ctx.video_processor.ui_results
                    if results:
                        st.success(f"å…±åµæ¸¬åˆ° {len(results)} å€‹æ•¸å­—")
                        st.session_state['last_cam_detected'] = len(results)
                        for line in results: st.markdown(line, unsafe_allow_html=True)
                    else:
                        st.warning("âš ï¸ ç•«é¢å‡çµäº†ï¼Œä½†æ²’æœ‰åµæ¸¬åˆ°æ•¸å­—ã€‚")
                        st.session_state['last_cam_detected'] = 0
                else:
                    st.info("â³ è«‹å…ˆç­‰å¾…é¡é ­ç•«é¢æŠ“æ‹å‡çµ (Captured)...")

        with col_btn2:
            if st.button("ğŸ”„ é‡æ–°æ”å½±", type="primary", use_container_width=True):
                if ctx.video_processor: ctx.video_processor.resume()
                st.session_state['last_cam_detected'] = 0
                st.rerun()

        st.write("---")
        manual_score = st.number_input("âœï¸ è¼¸å…¥æ­£ç¢ºæ•¸é‡", min_value=0, value=0, key=f"score_input_{st.session_state['input_key']}")
        st.write("##") 
        if st.button("ğŸ’¾ ä¸Šå‚³æˆç¸¾ä¸¦ç¹¼çºŒ", type="primary", use_container_width=True):
            total_add = st.session_state.get('last_cam_detected', 0)
            if total_add > 0 and manual_score >= total_add:
                st.error(f"âŒ éŒ¯èª¤ï¼šè¼¸å…¥æ•¸å€¼ ({manual_score}) è¶…éåµæ¸¬ç¸½æ•¸ ({total_add})")
            else:
                if ctx.video_processor: ctx.video_processor.resume()
                if total_add == 0: total_add = manual_score
                if manual_score > 0:
                    st.session_state['stats']['camera']['total'] += total_add
                    st.session_state['stats']['camera']['correct'] += manual_score
                    st.session_state['history']['camera'].append({'total': total_add, 'correct': manual_score})
                    st.toast(f"âœ… é¡é ­æ¨¡å¼ï¼šå·²è¨˜éŒ„ (ç¸½æ•¸{total_add}/æ­£ç¢º{manual_score})")
                    time.sleep(0.5)
                    st.session_state['input_key'] += 1
                st.rerun()

# ==============================================================================
# æ¨¡å¼ B: æ‰‹å¯«æ¿æ¨¡å¼
# ==============================================================================
elif app_mode == "ğŸ¨ æ‰‹å¯«æ¿æ¨¡å¼":
    with st.expander("ğŸ“– æ‰‹å¯«æ¨¡å¼æŒ‡å—(è«‹é»é–‹)", expanded=False):
        st.markdown("""
        * **æ›¸å¯«**ï¼šåœ¨é»‘è‰²ç•«å¸ƒå€ç›´æ¥ç”¨æ»‘é¼ æˆ–æ‰‹æŒ‡æ›¸å¯«æ•¸å­—ã€‚
        * **å·¥å…·**ï¼šå·¦å´å¯åˆ‡æ› **âœï¸ ç•«ç­†** æˆ– **ğŸ§½ æ©¡çš®æ“¦**ã€‚
        * **æ¸…é™¤**ï¼šæŒ‰ã€ŒğŸ—‘ï¸ æ¸…é™¤ã€å¯é‡ç½®ç•«å¸ƒèˆ‡è¨ˆæ•¸ã€‚
        * ä¿¡å¿ƒåº¦ä½æ–¼85ä¸æœƒè¨˜éŒ„
        """)
    
    if is_mobile: c_canvas = st.container(); c_res = st.container()
    else: c_canvas, c_res = st.columns([3, 2])

    with c_res:
        st.markdown("### ğŸ‘ï¸ çµæœ")
        res_ph = st.empty()
        if st.session_state['hw_result_img'] is not None: res_ph.image(st.session_state['hw_result_img'], channels="BGR", use_container_width=True)
        else: res_ph.info("è«‹åœ¨ç•«å¸ƒæ›¸å¯«")
    with c_res:
        st.divider()
        st.markdown("### ğŸ“ ç¢ºèªèˆ‡å­˜æª”")
        
        # å–å¾—ç›®å‰çš„åµæ¸¬æ•¸é‡
        current_cnt = st.session_state.get('hw_result_count', 0)
        
        # è¼¸å…¥æ­£ç¢ºæ•¸é‡
        # [ä¿®æ”¹é»] é€™è£¡åŠ ä¸Š max_value=current_cnt é™åˆ¶ä¸Šé™
        hw_manual_val = st.number_input(
            "æ­£ç¢ºæ•¸é‡", 
            min_value=0, 
            max_value=current_cnt,  # <--- åŠ å…¥é€™è¡Œé˜²å‘†ï¼Œé™åˆ¶ä¸èƒ½è¶…éåµæ¸¬æ•¸
            value=current_cnt, 
            key="hw_input_val"
        )
        
        # å­˜æª”æŒ‰éˆ•
        if st.button("ğŸ’¾ ä¸Šå‚³æ‰‹å¯«æˆç¸¾", type="primary", use_container_width=True):
            # [ä¿®æ”¹é»] é›™é‡æª¢æŸ¥ï¼šç¢ºä¿è¼¸å…¥å€¼ä¸å¤§æ–¼åµæ¸¬å€¼ (é›–ç„¶ UI æ“‹ä½äº†ï¼Œä½†å¾Œç«¯å†æª¢æŸ¥ä¸€æ¬¡æ›´ä¿éšª)
            if current_cnt > 0 and hw_manual_val >= current_cnt:
                st.error(f"âŒ éŒ¯èª¤ï¼šè¼¸å…¥æ•¸é‡ ({hw_manual_val}) ä¸èƒ½è¶…éåµæ¸¬ç¸½æ•¸ ({current_cnt})")
            elif hw_manual_val > 0:
                # å¯«å…¥çµ±è¨ˆæ•¸æ“š
                st.session_state['stats']['handwriting']['total'] += current_cnt
                st.session_state['stats']['handwriting']['correct'] += hw_manual_val
                
                # å¯«å…¥æ­·å²ç´€éŒ„
                st.session_state['history']['handwriting'].append({
                    'total': current_cnt, 
                    'correct': hw_manual_val
                })
                
                st.toast(f"âœ… å·²å„²å­˜ï¼(åµæ¸¬: {current_cnt} / æ­£ç¢º: {hw_manual_val})")
            else:
                st.warning("âš ï¸ æ•¸é‡ç‚º 0ï¼Œç„¡æ³•ä¸Šå‚³")

    with c_canvas:
        c_tool, c_clear = st.columns([2, 1])
        with c_tool: tool_mode = st.radio("ğŸ–Šï¸ å·¥å…·", ["âœï¸ ç•«ç­†", "ğŸ§½ æ©¡çš®æ“¦"], horizontal=True, label_visibility="collapsed")
        with c_clear:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤", use_container_width=True):
                # é‡ç½®ç•«å¸ƒèˆ‡ç›¸é—œç‹€æ…‹
                st.session_state['canvas_key'] = f"canvas_{time.time()}"
                st.session_state['tracker_state'] = {}
                st.session_state['box_cache'] = [] 
                st.session_state['next_id'] = 1
                st.session_state['hw_display_list'] = []
                st.session_state['hw_result_img'] = None
                st.session_state['hw_result_count'] = 0
                st.rerun()

        # æ‰‹å¯«æ¿åƒæ•¸
        merge_dist = 60       
        erosion_iter = 0      
        dilation_iter = 2     
        hw_min_area = 50

        # åˆå§‹åŒ–ç•«å¸ƒ
        canvas_result = st_canvas(
            fill_color="rgba(255, 165, 0, 0.3)",
            stroke_width=15 if tool_mode == "âœï¸ ç•«ç­†" else 40,
            stroke_color="#FFFFFF" if tool_mode == "âœï¸ ç•«ç­†" else "#000000",
            background_color="#000000",
            height=400 if not is_mobile else 230,
            width=850 if not is_mobile else 340,
            drawing_mode="freedraw",
            key=st.session_state.get('canvas_key', 'canvas_0'),
            display_toolbar=False,
            update_streamlit=True, 
        )

        # ç•«å¸ƒè®Šå‹•æ™‚çš„è™•ç†é‚è¼¯
        if canvas_result.image_data is not None:
            img_data = canvas_result.image_data.astype(np.uint8)
            if np.max(img_data) > 0:
                # è½‰ BGR æ ¼å¼
                if img_data.shape[2] == 4: img_bgr = cv2.cvtColor(img_data, cv2.COLOR_RGBA2BGR)
                else: img_bgr = img_data.copy()
                
                # å½±åƒå‰è™•ç†
                gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                blur = cv2.GaussianBlur(gray, (5, 5), 0)
                _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                binary_proc = thresh

                # å½¢æ…‹å­¸æ“ä½œ (ä¾µè•/è†¨è„¹)
                if erosion_iter > 0:
                    kernel = np.ones((3,3), np.uint8)
                    binary_proc = cv2.erode(binary_proc, kernel, iterations=erosion_iter)
                if dilation_iter > 0:
                    binary_proc = cv2.dilate(binary_proc, None, iterations=dilation_iter)

                # å°‹æ‰¾èˆ‡åˆä½µè¼ªå»“
                contours, _ = cv2.findContours(binary_proc, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                merged_items = merge_boxes_logic(contours, merge_dist_limit=merge_dist, time_limit=1.0)
                tracked_items = update_tracker_from_boxes(merged_items)
                
                draw_img = img_bgr.copy()
                batch_rois = []
                final_results_list = []
                valid_items = []
                
                # æº–å‚™é æ¸¬è³‡æ–™
                for item in tracked_items:
                    x, y, w, h = item['rect']
                    if w * h < hw_min_area: continue
                    roi = binary_proc[y:y+h, x:x+w]
                    
                    # è£½ä½œæ­£æ–¹å½¢å®¹å™¨
                    side = max(w, h)
                    pad = 40
                    container = np.zeros((side+pad, side+pad), dtype=np.uint8)
                    oy, ox = (side+pad-h)//2, (side+pad-w)//2
                    container[oy:oy+h, ox:ox+w] = roi
                    
                    # ç¸®æ”¾èˆ‡é‡å¿ƒç½®ä¸­
                    roi_ready = cv2.resize(container, (28, 28), interpolation=cv2.INTER_AREA)
                    final_roi = center_by_moments_cnn(roi_ready)
                    batch_rois.append(final_roi.astype('float32') / 255.0)
                    valid_items.append(item)

                detected_count = 0
                # é€²è¡Œé æ¸¬èˆ‡ç¹ªåœ–
                if len(batch_rois) > 0:
                    inputs = np.array(batch_rois).reshape(-1, 28, 28, 1)
                    preds = model.predict(inputs, verbose=0)
                    ui_idx = 1
                    for i, pred in enumerate(preds):
                        item = valid_items[i]
                        x, y, w, h = item['rect']
                        top_idx = pred.argsort()[-1]
                        conf = pred[top_idx]
                        
                        # ä¿¡å¿ƒåº¦éæ¿¾
                        if conf < CONFIDENCE_THRESHOLD: continue
                        
                        dx, dy = x + SHRINK_PX, y + SHRINK_PX
                        dw, dh = max(1, w - 2*SHRINK_PX), max(1, h - 2*SHRINK_PX)
                        cv2.rectangle(draw_img, (dx, dy), (dx+dw, dy+dh), (0, 255, 0), 2)
                        text_y = y - 10 if y > 25 else y + 30
                        cv2.putText(draw_img, str(top_idx), (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                        
                        final_results_list.append(f"<div><strong>#{ui_idx}</strong>: æ•¸å­— {top_idx} {get_bar_html(conf)}</div>")
                        detected_count += 1
                        ui_idx += 1

                res_ph.image(draw_img, channels="BGR", use_container_width=True)
                if final_results_list:
                    c_canvas.write("---")
                    cols = c_canvas.columns(2)
                    for idx, line in enumerate(final_results_list):
                        cols[idx%2].markdown(line, unsafe_allow_html=True)
                
                # æ›´æ–°ç‹€æ…‹
                st.session_state['hw_result_img'] = draw_img
                st.session_state['hw_result_count'] = detected_count

# ==============================================================================
# æ¨¡å¼ C: åœ–ç‰‡ä¸Šå‚³æ¨¡å¼
# ==============================================================================
elif app_mode == "ğŸ“ åœ–ç‰‡ä¸Šå‚³æ¨¡å¼":
    with st.expander("ğŸ“– åœ–ç‰‡ä¸Šå‚³åŠŸèƒ½æŒ‡å— (è«‹é»é–‹)", expanded=True):
        st.markdown("""
        **1. åŸºæœ¬æ“ä½œ**
        * é»æ“Š **Browse files** ä¸Šå‚³åœ–ç‰‡ï¼Œæˆ–é¸æ“‡ç¯„ä¾‹åœ–ç‰‡ã€‚
        * ç³»çµ±æœƒè‡ªå‹•æ¡†é¸åµæ¸¬åˆ°çš„æ•¸å­— (ç¶ æ¡†æˆ–æ©˜æ¡†)ã€‚
        
        **2. ç·¨è¼¯æ¨¡å¼ (ä¿®æ­£éŒ¯èª¤ç”¨)**
        * é–‹å•Ÿåœ–ç‰‡ä¸‹æ–¹çš„ **ã€ŒğŸ—‘ï¸ å•Ÿç”¨ç·¨è¼¯æ¨¡å¼ã€** é–‹é—œã€‚
        * **åˆªé™¤èª¤åˆ¤**ï¼šç›´æ¥é»æ“Šç•«é¢ä¸Šçš„ **ç¶ æ¡†** æˆ– **ç´«æ¡†** å³å¯åˆªé™¤ã€‚
        * **æ‰‹å‹•è£œé»**ï¼šè‹¥æœ‰æ•¸å­—æ²’è¢«æŠ“åˆ°ï¼Œè«‹é»æ“Šè©²æ•¸å­—çš„ **é»‘è‰²ç­†è·¡è™•**ï¼Œç³»çµ±æœƒå¼·åˆ¶åŠ å…¥è¾¨è­˜ (ç´«æ¡†)ã€‚
        * è‹¥é»äº†æ²’åæ‡‰å¯è€ƒæ…®å°‡åœ–ç‰‡ç¸®æ”¾å¾Œå†é»ä¸€æ¬¡
        """)
    
    # åˆå§‹åŒ–æœ¬æ¨¡å¼å°ˆç”¨çš„ Session State
    if 'ignored_boxes' not in st.session_state:
        st.session_state['ignored_boxes'] = set()
    if 'manual_boxes' not in st.session_state:
        st.session_state['manual_boxes'] = []

    # å¼•ç”¨ä¹‹å‰å®šç¾©çš„è¼”åŠ©å‡½å¼ (detect_image_source, merge_overlapping_boxes, etc.)
    # é€™è£¡ç›´æ¥ä½¿ç”¨ä¸Šæ–¹å…¨åŸŸå®šç¾©çš„å‡½å¼å³å¯ï¼Œç„¡éœ€é‡è¤‡å®šç¾©ã€‚
    
    # UI ä½ˆå±€
    layout_containers = get_responsive_layout([3, 1])
    col_up_left = layout_containers[0]
    col_up_right = layout_containers[1]
    
    with col_up_left:
        c_u1, c_u2 = st.columns([0.6, 0.4])
        with c_u1: uploaded_file = st.file_uploader("è«‹ä¸Šå‚³åœ–ç‰‡ (JPG, PNG)", type=['png', 'jpg', 'jpeg'])
        with c_u2:
            st.write("##")
            example_choice = st.selectbox("æˆ–ä½¿ç”¨ç¯„ä¾‹åœ–ç‰‡", ["è«‹é¸æ“‡...", "ç¯„ä¾‹ 1 (æ‰‹å¯«)", "ç¯„ä¾‹ 2 (æ‰‹å¯«)", "ç¯„ä¾‹ 3 (å°ç•«å®¶)", "ç¯„ä¾‹ 4 (éæ•¸å­—é¡)"])
            
            # é‡ç½®ç·¨è¼¯ç‹€æ…‹æŒ‰éˆ•
            if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰å¿½ç•¥/æ‰‹å‹•æ¡†", use_container_width=True):
                st.session_state['ignored_boxes'] = set()
                st.session_state['manual_boxes'] = [] 
                st.rerun()

        img, source_id = None, None
        # è¼‰å…¥ç¯„ä¾‹åœ–ç‰‡é‚è¼¯
        if example_choice != "è«‹é¸æ“‡...":
            ex_map = {"ç¯„ä¾‹ 1 (æ‰‹å¯«)": "examples/ex1.jpg", "ç¯„ä¾‹ 2 (æ‰‹å¯«)": "examples/ex2.jpg", "ç¯„ä¾‹ 3 (å°ç•«å®¶)": "examples/ex3.png", "ç¯„ä¾‹ 4 (éæ•¸å­—é¡)": "examples/ex4.jpg"}
            path = ex_map.get(example_choice)
            if os.path.exists(path): img, source_id = cv2.imread(path), path
            else: st.error(f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {path}")

        # è¼‰å…¥ä¸Šå‚³åœ–ç‰‡é‚è¼¯
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            img, source_id = cv2.imdecode(file_bytes, 1), uploaded_file.file_id
        
        # æª¢æ¸¬æ˜¯å¦åˆ‡æ›åœ–ç‰‡ï¼Œè‹¥æ˜¯å‰‡é‡ç½®ç·¨è¼¯ç‹€æ…‹
        if source_id != st.session_state.get('last_uploaded_file_id'):
            st.session_state['ignored_boxes'] = set()
            st.session_state['manual_boxes'] = [] 

        if img is not None:
            st.session_state['last_uploaded_file_id'] = source_id
            source_type = detect_image_source(img)
            display_img, gray = img.copy(), cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # --- å½±åƒäºŒå€¼åŒ–èˆ‡å‰è™•ç† ---
            if source_type == "photo":
                # ç…§ç‰‡æ¨¡å¼ï¼šä½¿ç”¨è‡ªé©æ‡‰é–¾å€¼è™•ç†å…‰ç…§ä¸å‡
                thresh = cv2.adaptiveThreshold(cv2.bilateralFilter(gray, 9, 75, 75), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 45, 12)
                binary_proc = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)))
                min_area_limit = 10 
            else:
                # æ•¸ä½æ¨¡å¼ï¼šç°¡å–®é–¾å€¼
                _, thresh = cv2.threshold(gray, 230, 255, cv2.THRESH_BINARY_INV)
                binary_proc = cv2.dilate(thresh, None, iterations=2)
                binary_proc = cv2.morphologyEx(binary_proc, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (20, 3)))
                min_area_limit = 5

            # --- è¼ªå»“æå–èˆ‡éæ¿¾ ---
            cnts, _ = cv2.findContours(binary_proc, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            raw_boxes = [cv2.boundingRect(c) for c in cnts if cv2.contourArea(c) > min_area_limit]
            sized_boxes = filter_small_boxes(merge_overlapping_boxes(raw_boxes), img.shape[0], img.shape[1], source_type)
            final_boxes = filter_low_contrast_boxes(sized_boxes, gray) if source_type == "photo" else sized_boxes

            # --- æº–å‚™é æ¸¬è³‡æ–™ ---
            batch_rois, batch_info = [], []
            for (x, y, w, h) in final_boxes:
                roi = binary_proc[y:y+h, x:x+w]
                if source_type == "photo" and h < 150: 
                    try: roi = deskew(roi)
                    except: pass 
                f_norm = preprocess_for_mnist(roi)
                
                # æª¢æŸ¥å­”æ´ (Hole Detection)
                has_hole = False
                c_sub, h_sub = cv2.findContours(f_norm, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
                if h_sub is not None:
                    for idx, cc in enumerate(c_sub):
                        if h_sub[0][idx][3] != -1 and cv2.contourArea(cc) > 5: has_hole = True; break
                
                batch_rois.append(f_norm.reshape(28, 28, 1).astype('float32') / 255.0)
                batch_info.append({"rect": (x, y, w, h), "has_hole": has_hole, "aspect": w/float(h), "flat": f_norm.reshape(1, 784).astype('float32') / 255.0})

            results_text, v_count = [], 1
            all_boxes_data = [] 
            
            # è¨ˆç®—é¡¯ç¤ºæ¯”ä¾‹å°º (åŸºæº–å¯¬åº¦ 800px)
            scale = max(1.0, img.shape[1] / 800.0)

            # --- [Part A] è‡ªå‹•åµæ¸¬çµæœç¹ªè£½ ---
            if batch_rois:
                preds = model.predict(np.stack(batch_rois), verbose=0)
                comb = sorted(list(zip(preds, batch_info)), key=lambda x: x[1]["rect"][0])
                
                for pred, info in comb:
                    bx, by, bw, bh = info["rect"]
                    box_id = f"{bx}_{by}_{bw}_{bh}" # å”¯ä¸€è­˜åˆ¥ç¢¼
                    
                    res_id = np.argmax(pred); conf = pred[res_id]
                    d_thr = 0.3 if source_type == "digital" else CONFIDENCE_THRESHOLD
                    if info["rect"][3] > 150: d_thr = 0.5

                    all_boxes_data.append({
                        "rect": (bx, by, bw, bh),
                        "id": box_id,
                        "conf": conf,
                        "thr": d_thr
                    })

                    is_ignored = box_id in st.session_state['ignored_boxes']

                    # è‹¥å·²è¢«ä½¿ç”¨è€…åˆªé™¤ (å¿½ç•¥)ï¼Œç¹ªè£½ç°è‰²å‰å‰æ¡†
                    if is_ignored:
                        cv2.rectangle(display_img, (bx, by), (bx+bw, by+bh), (128, 128, 128), 2)
                        cv2.line(display_img, (bx, by), (bx+bw, by+bh), (128, 128, 128), 2)
                        cv2.line(display_img, (bx+bw, by), (bx, by+bh), (128, 128, 128), 2)
                        continue

                    if conf < d_thr: continue
                    
                    # è¦å‰‡åº«å¾Œè™•ç†
                    if res_id == 7 and info["aspect"] < 0.25: res_id = 1
                    if res_id == 1 and info["has_hole"]: res_id = 0
                    if source_type == "digital" and info["aspect"] < 0.2: res_id = 1
                    
                    color, extra_msg, is_uncertain = (0, 255, 0), "", False
                    
                    # KNN äºŒæ¬¡é©—è­‰
                    if knn_model is not None and KNN_VERIFY_RANGE[0] <= conf <= 0.99:
                        try:
                            k_res = knn_model.predict(info["flat"])[0]
                            if k_res != res_id: extra_msg = f" (KNN: {k_res})"; is_uncertain = True; color = (0, 165, 255)
                        except: pass
                    
                    cv2.rectangle(display_img, (bx, by), (bx+bw, by+bh), color, max(2, int(3*scale)))
                    cv2.putText(display_img, str(res_id), (bx, by - TEXT_Y_OFFSET), cv2.FONT_HERSHEY_SIMPLEX, 1.0*scale, (0, 0, 255), max(2, int(3*scale)))
                    results_text.append(f"<div><strong>#{v_count}</strong>: {res_id} {extra_msg} {get_bar_html(conf, is_uncertain)}</div>")
                    v_count += 1
            
            # --- [Part B] æ‰‹å‹•åŠ å…¥çš„æ¡†ç¹ªè£½ ---
            if 'manual_boxes' in st.session_state:
                for mbox in st.session_state['manual_boxes']:
                    bx, by, bw, bh = mbox['rect']
                    lbl = mbox.get('label', mbox.get('digit', '?'))
                    conf = mbox['conf']
                    
                    # ç¹ªè£½ç´«è‰²æ‰‹å‹•æ¡†
                    cv2.rectangle(display_img, (bx, by), (bx+bw, by+bh), (255, 0, 255), max(2, int(3*scale)))
                    cv2.putText(display_img, str(lbl), (bx, by - 5), cv2.FONT_HERSHEY_SIMPLEX, 
                               1.0 * scale, (255, 0, 255), max(2, int(3*scale)))
                    
                    bar_html = get_bar_html(conf, is_uncertain=True)
                    results_text.append(f"<div><strong>#{v_count} (æ‰‹å‹•)</strong>: {lbl} {bar_html}</div>")
                    v_count += 1

            # å­˜æª”ä¾›é¡¯ç¤º
            st.session_state['upload_result_img'] = display_img
            st.session_state['upload_display_list'] = results_text
            st.session_state['upload_result_count'] = v_count - 1

        # --- é¡¯ç¤ºèˆ‡äº’å‹•é‚è¼¯ ---
        if st.session_state['upload_result_img'] is not None:
            
            st.write("---") 
            display_width = st.slider("ğŸ” åœ–ç‰‡é¡¯ç¤ºå¤§å° (æ‰‹æ©Ÿè‹¥è·‘ç‰ˆè«‹èª¿å°)ï¼Œåªæœ‰ç·¨è¼¯æ¨¡å¼èƒ½èª¿", min_value=300, max_value=1000, value=700)

            # ç¸®æ”¾åœ–ç‰‡ä»¥é©æ‡‰é¡¯ç¤ºå¯¬åº¦
            orig_h, orig_w = st.session_state['upload_result_img'].shape[:2]
            scale_ratio = display_width / float(orig_w)
            new_height = int(orig_h * scale_ratio)
            resized_display_img = cv2.resize(st.session_state['upload_result_img'], (display_width, new_height))
            resized_display_img_rgb = cv2.cvtColor(resized_display_img, cv2.COLOR_BGR2RGB)

            # ç·¨è¼¯æ¨¡å¼é–‹é—œ
            c_mode, c_info = st.columns([1, 2])
            with c_mode:
                delete_mode = st.toggle("ğŸ—‘ï¸ å•Ÿç”¨ç·¨è¼¯æ¨¡å¼", value=False, help="é–‹å•Ÿå¾Œï¼Œé»æ“Šç¶ æ¡†/ç´«æ¡†å¯åˆªé™¤ï¼›é»æ“Šé»‘è‰²ç­†è·¡å¯æ‰‹å‹•è£œæ¡†")
            with c_info:
                if delete_mode:
                    st.warning("âš ï¸ é»æ“Šç¶ æ¡†/ç´«æ¡†=åˆªé™¤ | é»æ“Šé»‘å­—=æ‰‹å‹•æ–°å¢")
                else:
                    st.info("é€™è®“æ•¸å­—è¢«åˆ¤å®šæˆé™°å½±æˆ–æ±¡æ¼¬æ™‚é‚„åŸæ•¸å­—ï¼Œå› æ­¤æœ‰äº›éæ•¸å­—é¡ä¹Ÿå®¹æ˜“è¢«èª¤åˆ¤")

            # æ ¹æ“šæ¨¡å¼æ±ºå®šé¡¯ç¤ºä¸€èˆ¬åœ–ç‰‡æˆ–å¯é»æ“Šåœ–ç‰‡
            if delete_mode:
                # ä½¿ç”¨ streamlit_image_coordinates ç²å–é»æ“Šåº§æ¨™
                value = streamlit_image_coordinates(
                    resized_display_img_rgb, 
                    key="click_img",
                    width=display_width 
                )

                if 'last_clicked_value' not in st.session_state:
                    st.session_state['last_clicked_value'] = None

                # åµæ¸¬åˆ°é»æ“Šäº‹ä»¶
                if value is not None and value != st.session_state['last_clicked_value']:
                    st.session_state['last_clicked_value'] = value
                    
                    # åº§æ¨™æ›ç®— (é¡¯ç¤ºåº§æ¨™ -> çœŸå¯¦åº§æ¨™)
                    click_x = value['x']
                    click_y = value['y']
                    real_x = int(click_x / scale_ratio)
                    real_y = int(click_y / scale_ratio)
                    
                    clicked_existing = False
                    
                    # 1. å„ªå…ˆæª¢æŸ¥æ˜¯å¦é»æ“Šåˆ°ã€Œæ‰‹å‹•æ¡†ã€ (ç´«è‰²) -> åˆªé™¤
                    if 'manual_boxes' in st.session_state:
                        for i, mbox in enumerate(st.session_state['manual_boxes']):
                            bx, by, bw, bh = mbox['rect']
                            if bx <= real_x <= bx + bw and by <= real_y <= by + bh:
                                st.session_state['manual_boxes'].pop(i)
                                st.toast("ğŸ—‘ï¸ å·²åˆªé™¤æ‰‹å‹•æ¡†")
                                clicked_existing = True
                                time.sleep(0.1)
                                st.rerun()
                                break
                    
                    # 2. æª¢æŸ¥ã€Œè‡ªå‹•æ¡†ã€ (ç¶ è‰²/ç°è‰²) -> åˆ‡æ›å¿½ç•¥ç‹€æ…‹
                    if not clicked_existing:
                        for box_data in all_boxes_data:
                            bx, by, bw, bh = box_data["rect"]
                            
                            if bx <= real_x <= bx + bw and by <= real_y <= by + bh:
                                box_id = box_data["id"]
                                
                                # ç©¿é€éš±å½¢æ¡†é‚è¼¯
                                if box_id not in st.session_state['ignored_boxes'] and box_data["conf"] < box_data["thr"]:
                                    continue 

                                if box_id in st.session_state['ignored_boxes']:
                                    st.session_state['ignored_boxes'].remove(box_id)
                                    st.toast(f"âœ… å·²æ¢å¾©è‡ªå‹•æ¡†")
                                else:
                                    st.session_state['ignored_boxes'].add(box_id)
                                    st.toast(f"ğŸ—‘ï¸ å·²åˆªé™¤è‡ªå‹•æ¡†")
                                clicked_existing = True
                                st.rerun()
                                break
                    
                    # 3. æ‰‹å‹•è£œé» (é»æ“Šç©ºç™½è™•) -> å˜—è©¦æ–°å¢
                    if not clicked_existing:
                        new_box_data, msg = try_add_manual_box(real_x, real_y, binary_proc, model)

                        if new_box_data:
                            st.session_state['manual_boxes'].append(new_box_data)
                            st.toast(msg)
                            time.sleep(0.5)
                            st.rerun()
                        else:
                            st.toast(msg)

            else:
                st.image(resized_display_img_rgb, use_container_width=True)
            
            # é¡¯ç¤ºè¾¨è­˜æ¸…å–®
            if st.session_state['upload_display_list']:
                st.divider(); st.markdown("#### ğŸ“Š è¾¨è­˜æ¸…å–®"); cols = st.columns(3)
                for i, h in enumerate(st.session_state['upload_display_list']): cols[i % 3].markdown(h, unsafe_allow_html=True)

    with col_up_right:
        st.markdown("### ğŸ“ ç¢ºèª")
        
        f_cnt = st.session_state.get('upload_result_count', 0)
        
        # æŒ‰éˆ•ç‹€æ…‹æ§åˆ¶
        is_disabled = False
        if (uploaded_file is not None or example_choice != "è«‹é¸æ“‡..."):
            if f_cnt > 0:
                st.success(f"åµæ¸¬åˆ° {f_cnt} å€‹")
            else:
                st.error("âš ï¸ ç„¡æ³•åµæ¸¬")
                is_disabled = True 
        else:
             is_disabled = True

        real_val = st.number_input(
            "æ­£ç¢ºæ•¸é‡", 
            min_value=0, 
            max_value=f_cnt, 
            value=f_cnt,      
            key="up_input_val", 
            disabled=is_disabled
        )
        
        # ä¸Šå‚³æ•¸æ“šæŒ‰éˆ•
        if st.button("ğŸ’¾ ä¸Šå‚³æˆç¸¾", type="primary", use_container_width=True, disabled=is_disabled):
            try:
                # ç¢ºä¿è³‡æ–™çµæ§‹å®Œæ•´
                if 'stats' not in st.session_state: st.session_state['stats'] = {}
                if 'upload' not in st.session_state['stats']: st.session_state['stats']['upload'] = {'total': 0, 'correct': 0}
                if 'history' not in st.session_state: st.session_state['history'] = {}
                if 'upload' not in st.session_state['history']: st.session_state['history']['upload'] = []

                # å¯«å…¥ Session
                st.session_state['stats']['upload']['total'] += f_cnt
                st.session_state['stats']['upload']['correct'] += real_val
                
                st.session_state['history']['upload'].append({
                    'total': f_cnt, 
                    'correct': real_val
                })
                
                st.toast(f"âœ… å·²å„²å­˜ï¼(åµæ¸¬: {f_cnt} / æ­£ç¢º: {real_val})")
                
                # æ¸…é™¤ç‹€æ…‹ä»¥æº–å‚™ä¸‹ä¸€æ¬¡ä¸Šå‚³
                st.session_state['upload_result_img'] = None
                st.session_state['last_uploaded_file_id'] = None
                st.session_state['ignored_boxes'] = set()
                st.session_state['manual_boxes'] = []
                st.session_state['upload_display_list'] = []
                st.session_state['upload_result_count'] = 0
                
                time.sleep(0.5)
                st.rerun()

            except Exception as e:
                st.error(f"âŒ éŒ¯èª¤: {str(e)}")