import streamlit as st
import cv2
import numpy as np
import os
import time
from PIL import Image
from streamlit_drawable_canvas import st_canvas # å¼•å…¥ç¹ªåœ–å¥—ä»¶

# è¨­å®š TensorFlow æ—¥èªŒç­‰ç´š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
from tensorflow.keras.models import load_model

# --- åƒæ•¸è¨­å®š ---
MIN_HEIGHT = 32
MIN_AREA = 140
SHRINK_PX = 4  # è¦–è¦ºå…§ç¸®

# --- 1. é é¢åˆå§‹åŒ–èˆ‡ Session State ---
st.set_page_config(page_title="æ‰‹å¯«è¾¨è­˜ (æ——è‰¦ç‰ˆ)", page_icon="ğŸ“", layout="wide")

# åˆå§‹åŒ–å…¨åŸŸè®Šæ•¸
if 'stats' not in st.session_state:
    st.session_state['stats'] = {'total': 0, 'correct': 0}
if 'last_photo' not in st.session_state:
    st.session_state['last_photo'] = None
if 'processed_image' not in st.session_state:
    st.session_state['processed_image'] = None
if 'detected_count' not in st.session_state:
    st.session_state['detected_count'] = 0
if 'input_locked' not in st.session_state:
    st.session_state['input_locked'] = False

# --- 2. è¼‰å…¥æ¨¡å‹ ---
@st.cache_resource
def load_ai_model():
    if os.path.exists("mnist_cnn.h5"):
        try:
            return load_model("mnist_cnn.h5")
        except:
            return None
    return None

model = load_ai_model()

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

def is_valid_content(img_bgr):
    """è†šè‰²/é›œè¨Šéæ¿¾å™¨"""
    if img_bgr is None or img_bgr.size == 0: return False
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    mean_h = np.mean(hsv[:,:,0]) 
    mean_s = np.mean(hsv[:,:,1]) 
    
    # 1. é£½å’Œåº¦éé«˜ -> é›œç‰©
    if mean_s > 60: return False 
    # 2. é£½å’Œåº¦ä¸­ç­‰ä¸”åç´… -> æ‰‹éƒ¨
    if 30 < mean_s <= 60:
        if (mean_h < 25 or mean_h > 155): return False 
    return True

def process_image(cv2_img, is_handwriting=False):
    """å½±åƒè™•ç†ã€CNNé æ¸¬ã€æ··åˆä¿®æ­£ã€ç•«åœ–"""
    # å‚™ä»½åŸåœ–ç”¨æ–¼ç•«æ¡†
    # å¦‚æœæ˜¯æ‰‹å¯«æ¿å‚³ä¾†çš„ RGBAï¼Œå…ˆè½‰æˆ BGR
    if cv2_img.shape[2] == 4:
        cv2_img = cv2.cvtColor(cv2_img, cv2.COLOR_RGBA2BGR)
        
    draw_img = cv2_img.copy()
    h_img, w_img = cv2_img.shape[:2]
    
    # å½±åƒå‰è™•ç†
    gray = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2GRAY)
    
    if is_handwriting:
        # æ‰‹å¯«æ¨¡å¼å·²ç¶“æ˜¯é»‘åº•ç™½å­—ï¼Œä¸éœ€è¦å¤ªå¼·çš„æ¨¡ç³Šèˆ‡äºŒå€¼åŒ–
        # ç›´æ¥å–ç”¨ (ç¨å¾®è†¨è„¹è®“ç·šæ¢é€£è²«)
        binary_proc = cv2.dilate(gray, None, iterations=1)
        # ç¢ºä¿çœŸçš„å¤ é»‘ç™½åˆ†æ˜
        _, binary_proc = cv2.threshold(binary_proc, 127, 255, cv2.THRESH_BINARY)
    else:
        # é¡é ­æ¨¡å¼ï¼šæ¨™æº–å‰è™•ç†
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 45, 18)
        binary_proc = cv2.dilate(thresh, None, iterations=2)

    # å°‹æ‰¾è¼ªå»“
    contours, hierarchy = cv2.findContours(binary_proc, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    
    valid_boxes = []
    if hierarchy is not None:
        for i, cnt in enumerate(contours):
            if hierarchy[0][i][3] == -1:
                area = cv2.contourArea(cnt)
                if area > MIN_AREA:
                    x, y, w, h = cv2.boundingRect(cnt)
                    has_hole = hierarchy[0][i][2] != -1
                    valid_boxes.append({
                        "box": (x, y, w, h), 
                        "has_hole": has_hole,
                        "aspect_ratio": w / float(h)
                    })

    valid_boxes = sorted(valid_boxes, key=lambda b: b["box"][0])

    # æº–å‚™æ‰¹é‡é æ¸¬
    batch_rois = []
    batch_info = []
    
    for item in valid_boxes:
        x, y, w, h = item["box"]
        
        # é¡é ­æ¨¡å¼æ‰éœ€è¦éæ¿¾é›œè¨Šï¼Œæ‰‹å¯«æ¨¡å¼ä¸ç”¨
        if not is_handwriting:
            if x < 15 or y < 15 or (x+w) > w_img-15 or (y+h) > h_img-15: continue
            if h < MIN_HEIGHT: continue
            # è†šè‰²éæ¿¾
            roi_color = cv2_img[y:y+h, x:x+w]
            if not is_valid_content(roi_color): continue

        # CNN Padding
        roi_single = binary_proc[y:y+h, x:x+w]
        side = max(w, h)
        padding = int(side * 0.2)
        container_size = side + padding * 2
        container = np.zeros((container_size, container_size), dtype=np.uint8)
        offset_y = (container_size - h) // 2
        offset_x = (container_size - w) // 2
        container[offset_y:offset_y+h, offset_x:offset_x+w] = roi_single
        
        roi_resized = cv2.resize(container, (28, 28), interpolation=cv2.INTER_AREA)
        roi_norm = roi_resized.astype('float32') / 255.0
        roi_ready = roi_norm.reshape(28, 28, 1)
        
        batch_rois.append(roi_ready)
        batch_info.append({
            "coords": (x, y, w, h),
            "has_hole": item["has_hole"],
            "aspect": item["aspect_ratio"]
        })

    detected_count = 0
    
    # åŸ·è¡Œé æ¸¬
    if len(batch_rois) > 0 and model is not None:
        batch_input = np.stack(batch_rois)
        predictions = model.predict(batch_input, verbose=0)
        
        for i, pred in enumerate(predictions):
            res_id = np.argmax(pred)
            confidence = np.max(pred)
            info = batch_info[i]
            x, y, w, h = info["coords"]
            has_hole = info["has_hole"]
            aspect = info["aspect"]

            # === æ··åˆä¿®æ­£é‚è¼¯ ===
            if res_id == 1:
                if aspect > 0.45: res_id = 7
            elif res_id == 7:
                if aspect < 0.25: res_id = 1
            if res_id == 7 and has_hole: res_id = 9
            if res_id == 9 and not has_hole and confidence < 0.95: res_id = 7
            if res_id == 0 and aspect < 0.5: res_id = 1
            # ===================

            # è¦–è¦ºå„ªåŒ– (å…§ç¸®æ¡†)
            draw_x = x + SHRINK_PX
            draw_y = y + SHRINK_PX
            draw_w = max(1, w - (SHRINK_PX * 2))
            draw_h = max(1, h - (SHRINK_PX * 2))

            cv2.rectangle(draw_img, (draw_x, draw_y), (draw_x+draw_w, draw_y+draw_h), (0, 255, 0), 2)
            cv2.putText(draw_img, str(res_id), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            detected_count += 1
            
    return draw_img, detected_count

# --- 4. ä»‹é¢ä½ˆå±€ ---

# å´é‚Šæ¬„
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶é¢æ¿")
    
    # [æ–°åŠŸèƒ½] æ¨¡å¼é¸æ“‡
    app_mode = st.radio("é¸æ“‡æ¨¡å¼", ["ğŸ“· æ”å½±æ©Ÿæ¨¡å¼", "ğŸ¨ æ‰‹å¯«æ¿æ¨¡å¼"])
    
    st.divider()
    
    # çµ±è¨ˆæ•¸æ“š
    total = st.session_state['stats']['total']
    correct = st.session_state['stats']['correct']
    acc = (correct / total * 100) if total > 0 else 0.0
    
    st.metric("ç´¯ç©ç¸½æ•¸", total)
    st.metric("ç´¯ç©æ­£ç¢º", correct)
    st.metric("æº–ç¢ºç‡", f"{acc:.1f}%")
    
    if st.button("ğŸ”„ é‡ç½®çµ±è¨ˆ"):
        st.session_state['stats'] = {'total': 0, 'correct': 0}
        st.rerun()

# ä¸»ç•«é¢
st.title("ğŸ“ æ‰‹å¯«æ•¸å­—è¾¨è­˜ç³»çµ± (Web æ——è‰¦ç‰ˆ)")

if model is None:
    st.error("âŒ æ‰¾ä¸åˆ° `mnist_cnn.h5`ï¼è«‹ç¢ºèªæª”æ¡ˆä½ç½®ã€‚")
    st.stop()

# --- 5. æ¨¡å¼åˆ†æ”¯è™•ç† ---

current_img = None
is_handwriting_mode = (app_mode == "ğŸ¨ æ‰‹å¯«æ¿æ¨¡å¼")

if is_handwriting_mode:
    st.info("è«‹åœ¨ä¸‹æ–¹é»‘æ¿ç›´æ¥æ›¸å¯«æ•¸å­—ï¼Œæ”¾é–‹æ»‘é¼ å³è‡ªå‹•è¾¨è­˜ã€‚")
    # æ‰‹å¯«æ¿å…ƒä»¶
    canvas_result = st_canvas(
        fill_color="rgba(255, 165, 0, 0.3)",  # å¡«å……è‰² (æ²’ç”¨åˆ°)
        stroke_width=15,                      # ç­†åˆ·ç²—ç´°
        stroke_color="#FFFFFF",               # ç­†åˆ·é¡è‰² (ç™½)
        background_color="#000000",           # èƒŒæ™¯é¡è‰² (é»‘)
        height=300,
        width=600,
        drawing_mode="freedraw",
        key="canvas",
    )
    
    # ç•¶ç•«å¸ƒæœ‰å…§å®¹æ™‚ï¼Œé€²è¡Œè™•ç†
    if canvas_result.image_data is not None:
        # è½‰æ›ç‚º OpenCV æ ¼å¼ (RGBA)
        img_data = canvas_result.image_data.astype(np.uint8)
        # æª¢æŸ¥æ˜¯å¦å…¨é»‘ (æ²’ç•«æ±è¥¿)
        if np.max(img_data) > 0:
            current_img = img_data

else:
    # æ”å½±æ©Ÿæ¨¡å¼
    img_file_buffer = st.camera_input("ğŸ“¸ è«‹å°æº–æ•¸å­—ï¼ŒæŒ‰ä¸‹æ‹ç…§æŒ‰éˆ•é€²è¡Œè¾¨è­˜")
    if img_file_buffer is not None:
        # æª¢æŸ¥æ˜¯å¦æ˜¯æ–°ç…§ç‰‡
        if img_file_buffer != st.session_state['last_photo']:
            bytes_data = img_file_buffer.getvalue()
            current_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
            st.session_state['last_photo'] = img_file_buffer

# --- 6. çµ±ä¸€è™•ç†æµç¨‹ ---

if current_img is not None:
    # åŸ·è¡Œæ ¸å¿ƒè¾¨è­˜
    processed_img, count = process_image(current_img, is_handwriting=is_handwriting_mode)
    
    # æ›´æ–°é¡¯ç¤ºç‹€æ…‹
    st.session_state['processed_image'] = processed_img
    st.session_state['detected_count'] = count
    st.session_state['input_locked'] = False

    # é¡¯ç¤ºçµæœ
    st.image(st.session_state['processed_image'], channels="BGR", use_column_width=True)
    
    # é¡¯ç¤ºæª¢æ¸¬æ•¸é‡
    det_count = st.session_state['detected_count']
    if det_count > 0:
        if is_handwriting_mode:
            st.success(f"âœ¨ æ‰‹å¯«æ¿åµæ¸¬åˆ° **{det_count}** å€‹æ•¸å­—")
        else:
            st.info(f"ğŸ” ç•«é¢ä¸­åµæ¸¬åˆ° **{det_count}** å€‹æ•¸å­—")
    else:
        if not is_handwriting_mode:
            st.warning("âš ï¸ æœªåµæ¸¬åˆ°æ•¸å­—")

    # æˆç¸¾è¼¸å…¥å€
    st.write("---")
    col1, col2 = st.columns([2, 1])
    
    with col1:
        manual_score = st.number_input(
            "âœï¸ è«‹è¼¸å…¥æ­£ç¢ºæ•¸å­—æ•¸é‡", 
            min_value=0, 
            max_value=det_count, 
            value=det_count,
            disabled=st.session_state['input_locked'],
            key=f"input_{time.time()}" # å¼·åˆ¶æ›´æ–° key é¿å…å¡ä½
        )
    
    with col2:
        st.write("##") 
        if st.button("ğŸ’¾ ç¢ºèªä¸¦å„²å­˜", type="primary", disabled=st.session_state['input_locked']):
            if det_count > 0:
                st.session_state['stats']['total'] += det_count
                st.session_state['stats']['correct'] += manual_score
                st.session_state['input_locked'] = True
                
                success_msg = st.success("âœ… æˆç¸¾å·²å„²å­˜ï¼")
                time.sleep(1)
                success_msg.empty()
                st.rerun()